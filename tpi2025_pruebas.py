# -*- coding: utf-8 -*-
"""TPI2025-pruebas

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/jeremyandrada/tpi2025-pruebas.67f494fd-0fd9-4db2-ac5d-161da5f7c790.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251107/auto/storage/goog4_request%26X-Goog-Date%3D20251107T165040Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4f5bbed20954f1cdd143f1781dab74b2924fb62da0476663c01122da966a3ea4b85a63109a00acabe8690c2294ebf5d0af116cc4ea2549ddc098c955be06d0d2f9160f51f9a38fa61c416103b2445f7817ef61820a18a780ae170e592e61bef8ff3ff1c39d74ca2fa43a80c590035d71633a2cd4e7d2bfea3596c35efa8b1e2cb3b16decfd3561dcbd3f02570c4eecf2254c4536eb798d6fabd636525f2c2564cc438c1d0b0be53a692ff34206c285d85645f6e1b757c62bcfd149ad9deb9fdd315515819d07baf48b0d7208c65a1f2a6ed6e4d45e44ebc16e3e470204a599ee1cbe0ccb36c581f65285234501767830ffd87c42655e46845271ac6b45e9e559

# *TPI - Sistema de B√∫squeda Multimodal de Im√°genesFRC UTN - Primavera 2025*
"""

#EJECUTAR PRIMERO
!pip install -q git+https://github.com/openai/CLIP.git faiss-cpu ftfy regex tqdm

#1. CONFIGURACI√ìN DE RUTAS E IMPORTS


import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from pathlib import Path
from collections import Counter
import warnings
warnings.filterwarnings('ignore')
import pickle
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForCausalLM
import clip
import faiss

import random

# Fijar semillas
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)



# Configuraci√≥n
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Dispositivo: {DEVICE}")
print(f"üî• PyTorch: {torch.__version__}")
print(f"‚úÖ CUDA disponible: {torch.cuda.is_available()}")

# Rutas (ajustar seg√∫n Kaggle)
DATA_PATH = "/kaggle/input/tpi-frc-utn-2025-primavera/dataset/VOC2012_train_val/VOC2012_train_val/JPEGImages"
QUESTIONS_PATH = "/kaggle/input/tpi-frc-utn-2025-primavera/questions.csv"
ANNOTATIONS_PATH = "/kaggle/input/tpi-frc-utn-2025-primavera/dataset/VOC2012_train_val/VOC2012_train_val/Annotations"

print(f"\nüìÅ Verificando rutas...")
print(f"   Im√°genes: {'‚úÖ' if os.path.exists(DATA_PATH) else '‚ùå'} {DATA_PATH}")
print(f"   Questions: {'‚úÖ' if os.path.exists(QUESTIONS_PATH) else '‚ùå'} {QUESTIONS_PATH}")
print(f"   Annotations: {'‚úÖ' if os.path.exists(ANNOTATIONS_PATH) else '‚ùå'} {ANNOTATIONS_PATH}")

if os.path.exists(DATA_PATH):
    image_files = [f for f in os.listdir(DATA_PATH) if f.endswith('.jpg')]
    print(f"\nüìä Total de im√°genes encontradas: {len(image_files)}")
else:
    print("\n‚ùå ERROR: No se encontr√≥ la carpeta de im√°genes")
    print("   Por favor, ajusta DATA_PATH manualmente")


print(f"üé≤ Semilla aleatoria fijada: {SEED}")

"""2. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)"""

print("1. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)")


image_files = sorted([f for f in os.listdir(DATA_PATH) if f.endswith('.jpg')])
print(f"\nüìä Total de im√°genes: {len(image_files)}")


def load_image_metadata(data_path, sample_size=1000):
    """
    Carga metadata de im√°genes
    Si hay muchas im√°genes, usa una muestra para rapidez
    """
    all_files = [f for f in os.listdir(data_path) if f.endswith('.jpg')]

    # Si hay muchas im√°genes, tomar muestra
    if len(all_files) > sample_size:
        print(f"‚ö° Analizando muestra de {sample_size} im√°genes de {len(all_files)} totales")
        sample_files = np.random.choice(all_files, sample_size, replace=False)
    else:
        sample_files = all_files

    metadata = []
    total = len(sample_files)

    # Usar enumerate en lugar de tqdm
    for i, img_name in enumerate(sample_files):
        # Mostrar progreso cada 100 im√°genes
        if (i + 1) % 100 == 0:
            print(f"   Procesadas {i+1}/{total} im√°genes...")

        try:
            img_path = os.path.join(data_path, img_name)
            img = Image.open(img_path)

            metadata.append({
                'image_id': img_name.replace('.jpg', ''),
                'width': img.width,
                'height': img.height,
                'aspect_ratio': img.width / img.height,
                'mode': img.mode,
                'size_kb': os.path.getsize(img_path) / 1024
            })
        except Exception as e:
            print(f"Error en {img_name}: {e}")
            continue

    print(f"   ‚úÖ Completado: {len(metadata)}/{total} im√°genes cargadas")
    return pd.DataFrame(metadata)


df_images = load_image_metadata(DATA_PATH, sample_size=1000)
print(f"‚úÖ Metadata cargada: {len(df_images)} im√°genes")


# Estad√≠sticas b√°sicas
print("\n=== ESTAD√çSTICAS DE IM√ÅGENES ===")
print(df_images[['width', 'height', 'aspect_ratio', 'size_kb']].describe())


# Visualizaci√≥n 1: Distribuciones
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Ancho
axes[0, 0].hist(df_images['width'], bins=40, edgecolor='black', color='steelblue')
axes[0, 0].set_title('Distribuci√≥n de Anchos', fontsize=12, fontweight='bold')
axes[0, 0].set_xlabel('Ancho (p√≠xeles)')
axes[0, 0].set_ylabel('Frecuencia')
axes[0, 0].grid(alpha=0.3)

# Alto
axes[0, 1].hist(df_images['height'], bins=40, edgecolor='black', color='coral')
axes[0, 1].set_title('Distribuci√≥n de Altos', fontsize=12, fontweight='bold')
axes[0, 1].set_xlabel('Alto (p√≠xeles)')
axes[0, 1].set_ylabel('Frecuencia')
axes[0, 1].grid(alpha=0.3)

# Aspect Ratio
axes[1, 0].hist(df_images['aspect_ratio'], bins=40, edgecolor='black', color='mediumseagreen')
axes[1, 0].set_title('Distribuci√≥n de Aspect Ratios', fontsize=12, fontweight='bold')
axes[1, 0].set_xlabel('Aspect Ratio (width/height)')
axes[1, 0].set_ylabel('Frecuencia')
axes[1, 0].grid(alpha=0.3)

# Tama√±o de archivos
axes[1, 1].hist(df_images['size_kb'], bins=40, edgecolor='black', color='mediumpurple')
axes[1, 1].set_title('Distribuci√≥n de Tama√±os de Archivo', fontsize=12, fontweight='bold')
axes[1, 1].set_xlabel('Tama√±o (KB)')
axes[1, 1].set_ylabel('Frecuencia')
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('eda_distributions.png', dpi=150, bbox_inches='tight')
plt.show()

# Muestra de im√°genes
def show_random_images(data_path, n=12):
    """Muestra n im√°genes aleatorias"""
    all_files = [f for f in os.listdir(data_path) if f.endswith('.jpg')]
    sample_imgs = np.random.choice(all_files, min(n, len(all_files)), replace=False)

    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    axes = axes.flatten()

    for idx, img_name in enumerate(sample_imgs):
        img_path = os.path.join(data_path, img_name)
        img = Image.open(img_path)

        axes[idx].imshow(img)
        axes[idx].set_title(f"{img_name[:15]}...\n{img.width}x{img.height}", fontsize=8)
        axes[idx].axis('off')

    plt.suptitle('Muestra Aleatoria de Im√°genes del Dataset', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('random_samples.png', dpi=150, bbox_inches='tight')
    plt.show()

show_random_images(DATA_PATH, n=12)


#Analisis de clases

import xml.etree.ElementTree as ET

if os.path.exists(ANNOTATIONS_PATH):
    print("\n=== AN√ÅLISIS DE CLASES ===")

    ann_files = [f for f in os.listdir(ANNOTATIONS_PATH) if f.endswith('.xml')]
    all_labels = []

    for ann_file in ann_files[:1000]:  # Muestra
        try:
            tree = ET.parse(os.path.join(ANNOTATIONS_PATH, ann_file))
            root = tree.getroot()
            for obj in root.findall('object'):
                label = obj.find('name').text
                all_labels.append(label)
        except:
            continue

    label_counts = Counter(all_labels)

    # Visualizaci√≥n
    top_classes = label_counts.most_common(20)
    classes, counts = zip(*top_classes)

    plt.figure(figsize=(12, 6))
    plt.barh(range(len(classes)), counts, color='steelblue')
    plt.yticks(range(len(classes)), classes)
    plt.xlabel('Frecuencia')
    plt.title('Top 20 Clases en Pascal VOC 2012')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()

"""3. GENERACI√ìN DE EMBEDDINGS CON CLIP"""

print("\n=== Cargando modelo CLIP ===")
model, preprocess = clip.load("ViT-B/32", device=DEVICE)
model.eval()

def generate_image_embeddings(data_path, model, preprocess, device, batch_size=32):
    """Genera embeddings para todas las im√°genes"""
    image_files = sorted(Path(data_path).glob("*.jpg"))
    embeddings = []
    image_ids = []

    print(f"Generando embeddings para {len(image_files)} im√°genes...")

    for i in range(0, len(image_files), batch_size):
        batch_files = image_files[i:i+batch_size]
        batch_images = []

        for img_path in batch_files:
            try:
                img = Image.open(img_path).convert('RGB')
                img_tensor = preprocess(img)
                batch_images.append(img_tensor)
                image_ids.append(img_path.stem)
            except Exception as e:
                print(f"Error procesando {img_path}: {e}")
                continue

        if batch_images:
            batch_tensor = torch.stack(batch_images).to(device)

            with torch.no_grad():
                batch_embeddings = model.encode_image(batch_tensor)
                batch_embeddings = F.normalize(batch_embeddings, dim=-1)

            embeddings.append(batch_embeddings.cpu().numpy())

        if (i // batch_size + 1) % 10 == 0:
            print(f"Procesadas {i + len(batch_files)} im√°genes...")

    embeddings = np.vstack(embeddings)
    print(f"Embeddings generados: {embeddings.shape}")

    return embeddings, image_ids

# Generar embeddings
image_embeddings, image_ids = generate_image_embeddings(DATA_PATH, model, preprocess, DEVICE)

"""4. INDEXACI√ìN CON FAISS"""

print("\n=== Creando √≠ndice FAISS ===")
dimension = image_embeddings.shape[1]
index = faiss.IndexFlatIP(dimension)  # Inner Product (cosine similarity)
index.add(image_embeddings.astype('float32'))
print(f"√çndice creado con {index.ntotal} vectores de dimensi√≥n {dimension}")


#Guardar embeddings e indice para no tener que recalcuarlos
def save_embeddings_and_index(image_embeddings, image_ids, index,
                              emb_path='image_embs.npy',
                              ids_path='image_ids.pkl',
                              faiss_path='faiss.index'):
    """Guardar para reutilizar sin recalcular"""
    np.save(emb_path, image_embeddings.astype('float32'))
    with open(ids_path, 'wb') as f:
        pickle.dump(image_ids, f)
    faiss.write_index(index, faiss_path)
    print("‚úÖ Embeddings, IDs y FAISS index guardados.")

# Guardar despu√©s de generar
save_embeddings_and_index(image_embeddings, image_ids, index)

"""5. B√öSQUEDA BASELINE (CLIP)"""

def search_baseline(query, model, index, image_ids, device, k=10):
    """B√∫squeda baseline con CLIP"""
    # Tokenizar query
    text_tokens = clip.tokenize([query]).to(device)

    # Generar embedding de texto
    with torch.no_grad():
        text_embedding = model.encode_text(text_tokens)
        text_embedding = F.normalize(text_embedding, dim=-1)

    # B√∫squeda en FAISS
    query_vector = text_embedding.cpu().numpy().astype('float32')
    distances, indices = index.search(query_vector, k)

    # Resultados
    results = [image_ids[idx] for idx in indices[0]]
    scores = distances[0].tolist()

    return results, scores

"""# Generacion de submission.csv BASELINE, sin mejoras"""

df_questions = pd.read_csv(QUESTIONS_PATH)
submissions = []

for idx, row in df_questions.iterrows():
    qid = row['qid']
    query = row['query']
    print(f"Procesando {qid}: {query}")

    # Usamos solo el baseline: CLIP + FAISS
    results, _ = search_baseline(query, model, index, image_ids, DEVICE, k=10)
    preds = ";".join(results[:10])

    submissions.append({'qid': qid, 'preds': preds})

df_submission = pd.DataFrame(submissions)
df_submission.to_csv('submission.csv', index=False)
print("‚úÖ Archivo submission.csv generado correctamente.")

"""6. MEJORA CON LLM"""

!pip install -q groq

from groq import Groq
import os

# IMPORTANTE: Obtener tu API key en https://console.groq.com/keys
GROQ_API_KEY = "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"  # ‚Üê REEMPLAZAR CON TU KEY

try:
    groq_client = Groq(api_key=GROQ_API_KEY)
    LLM_AVAILABLE = True
    print("‚úÖ Groq API configurada")
except:
    LLM_AVAILABLE = False
    print("‚ö†Ô∏è Groq no disponible, usando diccionario")


# 2. Funci√≥n de reformulaci√≥n con LLM
def reformulate_query(query):
    """Reformula con Groq LLM (con fallback a diccionario)"""

    # Intentar con LLM
    if LLM_AVAILABLE:
        try:
            response = groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "Translate image search queries to English. Be concise."},
                    {"role": "user", "content": f"Translate: {query}"}
                ],
                model="llama-3.1-8b-instant",
                temperature=0.3,
                max_tokens=30
            )
            reformulated = response.choices[0].message.content.strip()
            return reformulated, "Groq LLM"
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error Groq: {str(e)[:50]}")

    # Fallback: diccionario
    reformulated = translate_query(query)
    return reformulated, "Diccionario"

"""7. RERANKING CON FILTROS COMPLEJOS"""

def extract_constraints(query):
    """Extrae restricciones de la query (negaciones, atributos)"""
    constraints = {
        'required': [],
        'forbidden': [],
        'attributes': []
    }

    # Detectar negaciones simples
    negation_phrases = [
        "sin ", "que no ", "pero sin ", "no sea ", "no est√© ",
        "without ", "but not ", "no ", "not "
    ]

    query_lower = query.lower()

    # Extraer t√©rminos prohibidos
    for phrase in negation_phrases:
        if phrase in query_lower:
            parts = query_lower.split(phrase)
            if len(parts) > 1:
                forbidden_term = parts[1].split()[0] if parts[1].split() else ""
                if forbidden_term:
                    constraints['forbidden'].append(forbidden_term)

    return constraints

def rerank_with_constraints(initial_results, query, model, preprocess, device, image_ids, data_path):
    """Reranking considerando restricciones complejas"""
    constraints = extract_constraints(query)

    # Si no hay restricciones, retornar resultados originales
    if not constraints['forbidden']:
        return initial_results

    reranked = []

    for img_id in initial_results:
        # Cargar imagen
        img_path = Path(data_path) / f"{img_id}.jpg"
        if not img_path.exists():
            continue

        img = Image.open(img_path).convert('RGB')
        img_tensor = preprocess(img).unsqueeze(0).to(device)

        # Verificar t√©rminos prohibidos
        penalty = 0
        for forbidden_term in constraints['forbidden']:
            text_tokens = clip.tokenize([forbidden_term]).to(device)

            with torch.no_grad():
                img_features = model.encode_image(img_tensor)
                text_features = model.encode_text(text_tokens)

                img_features = F.normalize(img_features, dim=-1)
                text_features = F.normalize(text_features, dim=-1)

                similarity = (img_features @ text_features.T).item()

                # Si hay alta similitud con t√©rmino prohibido, aplicar penalizaci√≥n
                if similarity > 0.25:
                    penalty += similarity

        reranked.append((img_id, -penalty))  # Menor penalizaci√≥n = mejor

    # Ordenar por penalizaci√≥n
    reranked.sort(key=lambda x: x[1], reverse=True)

    return [img_id for img_id, _ in reranked]
print("LISTO")

"""8. PIPELINE COMPLETO"""

def search_with_improvements(query, model, llm_model, llm_tokenizer, index, image_ids,
                            device, data_path, preprocess, k=10, use_reformulation=True,
                            use_reranking=True):

    # Reformular query si corresponde
    if use_reformulation:
        query_reformulated = reformulate_query(query)

        # ‚úÖ CORRECCI√ìN: Verificar si retorna tupla y extraer el string
        if isinstance(query_reformulated, tuple):
            query_reformulated = query_reformulated[0]  # Tomar primer elemento

        # Asegurar que sea string
        if not isinstance(query_reformulated, str):
            query_reformulated = str(query_reformulated)

        # Log de reformulaci√≥n
        if query_reformulated != query.lower():
            print(f"   üìù Reformulada: '{query_reformulated}'")
    else:
        query_reformulated = query

    # B√∫squeda baseline (traer m√°s candidatos para reranking)
    results_baseline, scores = search_baseline(query_reformulated, model, index, image_ids, device, k=k*3)

    # Reranking si hay restricciones
    query_lower = query.lower()
    if use_reranking and any(word in query_lower for word in ['sin', 'pero', 'que no', 'without', 'but not', 'no ']):
        print(f"   üö´ Aplicando reranking...")
        results_final = rerank_with_constraints(results_baseline, query, model, preprocess, device, image_ids, data_path)
        results_final = results_final[:k]
    else:
        results_final = results_baseline[:k]

    # Garantizar longitud 10, sin duplicados y que los IDs existan
    final_list = []
    seen = set()

    for img_id in results_final:
        if len(final_list) >= k:
            break
        if img_id in seen:
            continue
        # Verificar existencia del archivo
        if os.path.exists(os.path.join(data_path, f"{img_id}.jpg")):
            final_list.append(img_id)
            seen.add(img_id)

    # Si faltan, completar con los siguientes de baseline
    if len(final_list) < k:
        for img_id in results_baseline:
            if len(final_list) >= k:
                break
            if img_id in seen:
                continue
            if os.path.exists(os.path.join(data_path, f"{img_id}.jpg")):
                final_list.append(img_id)
                seen.add(img_id)

    # Fallback: si sigue faltando, a√±adir im√°genes aleatorias
    if len(final_list) < k:
        all_ids = [p.stem for p in Path(data_path).glob("*.jpg")]
        for img_id in all_ids:
            if len(final_list) >= k:
                break
            if img_id not in seen:
                final_list.append(img_id)
                seen.add(img_id)

    return final_list

"""9. GENERACION DE SUBMISSION.CSV CON MEJORAS LLM O RERANKING"""

df_questions = pd.read_csv(QUESTIONS_PATH)
print(f"\nTotal de queries: {len(df_questions)}")

submissions = []
for idx, row in df_questions.iterrows():
    qid = row['qid']
    query = row['query']
    print(f"Procesando {qid}: {query}")

    use_llm = int(qid[1:]) >= 21
    use_rerank = int(qid[1:]) >= 21

    res = search_with_improvements(
        query, model, llm_model, llm_tokenizer, index, image_ids,
        DEVICE, DATA_PATH, preprocess,
        k=10,
        use_reformulation=use_llm,
        use_reranking=use_rerank
    )

    # Asegurar 10 preds √∫nicos
    preds = ";".join(res[:10])
    submissions.append({'qid': qid, 'preds': preds})

df_submission = pd.DataFrame(submissions)
df_submission.to_csv('submission.csv', index=False)
print("‚úÖ Archivo submission.csv generado: submission.csv")
# Validaci√≥n final
for idx, row in df_submission.iterrows():
    preds = [p.strip() for p in row['preds'].split(';') if p.strip()]
    if len(preds) != 10:
        print(f"‚ö†Ô∏è {row['qid']} tiene {len(preds)} preds")

"""# Comparacion visual: Baseline vs LLM + Reranking"""

def compare_methods_visual(query, qid=None):
    """
    Compara visualmente 3 m√©todos:
    1. Baseline (solo CLIP)
    2. Con reformulaci√≥n LLM
    3. Con reformulaci√≥n + reranking
    """
    print(f"\n{'='*70}")
    print(f"COMPARACI√ìN PARA: '{query}'")
    print(f"{'='*70}")

    # M√©todo 1: Baseline
    results_baseline, _ = search_baseline(query, model, index, image_ids, DEVICE, k=10)

    # M√©todo 2: Con reformulaci√≥n
    query_ref, method = reformulate_query(query)
    if isinstance(query_ref, tuple):
        query_ref = query_ref[0]

    results_llm, _ = search_baseline(query_ref, model, index, image_ids, DEVICE, k=10)


    # M√©todo 3: Con reformulaci√≥n + reranking
    results_full = search_with_improvements(
        query, model, None, None, index, image_ids,
        DEVICE, DATA_PATH, preprocess, k=10,
        use_reformulation=True, use_reranking=True
    )


    # Visualizaci√≥n lado a lado
    fig, axes = plt.subplots(3, 5, figsize=(18, 12))

    methods = [
        ("Baseline", results_baseline),
        ("+ Reformulaci√≥n", results_llm),
        ("+ Reformulaci√≥n + Reranking", results_full)
    ]

    for row_idx, (method_name, results) in enumerate(methods):
        for col_idx in range(5):
            ax = axes[row_idx, col_idx]

            if col_idx < len(results):
                img_path = os.path.join(DATA_PATH, f"{results[col_idx]}.jpg")
                if os.path.exists(img_path):
                    img = Image.open(img_path)
                    ax.imshow(img)
                    ax.set_title(f"#{col_idx+1}\n{results[col_idx][:12]}...", fontsize=7)

            ax.axis('off')

        # Etiqueta de m√©todo a la izquierda
        axes[row_idx, 0].text(-0.3, 0.5, method_name,
                             transform=axes[row_idx, 0].transAxes,
                             fontsize=10, fontweight='bold',
                             verticalalignment='center',
                             rotation=90)

    plt.suptitle(f"Comparaci√≥n de M√©todos\nQuery: '{query}'",
                 fontsize=14, fontweight='bold')
    plt.tight_layout()

    # Guardar con nombre √∫nico
    filename = f"comparison_{qid if qid else 'example'}.png"
    plt.savefig(filename, dpi=150, bbox_inches='tight')
    plt.show()

    return results_baseline, results_llm, results_full


# Ejecutar comparaciones para queries de ejemplo
queries_comparar = [
    ('q1', 'aeroplane'),
    ('q7', 'car'),
    ('q21', 'auto rojo durante la noche'),
    ('q22', 'mujer con sombrero pero sin lentes'),
    ('q28', 'bicicleta junto a un √°rbol sin autos ni personas alrededor')
]

print("\n" + "="*70)
print("COMPARACIONES VISUALES")
print("="*70)

for qid, query in queries_comparar:
    compare_methods_visual(query, qid)

"""# Metricas de recuperacion"""

def calculate_precision_at_k(results, ground_truth, k=10):
    """
    Calcula Precision@K
    """
    relevant_found = sum(1 for r in results[:k] if r in ground_truth)
    return relevant_found / k if k > 0 else 0


def compare_metrics(qid, query, ground_truth_ids):
    """
    Compara m√©tricas entre m√©todos
    """
    # Baseline
    results_baseline, _ = search_baseline(query, model, index, image_ids, DEVICE, k=10)
    p_baseline = calculate_precision_at_k(results_baseline, ground_truth_ids, k=10)

    # Con reformulaci√≥n
    query_ref, _ = reformulate_query(query)
    if isinstance(query_ref, tuple):
        query_ref = query_ref[0]
    results_llm, _ = search_baseline(query_ref, model, index, image_ids, DEVICE, k=10)
    p_llm = calculate_precision_at_k(results_llm, ground_truth_ids, k=10)

    # Full pipeline
    results_full = search_with_improvements(
        query, model, None, None, index, image_ids,
        DEVICE, DATA_PATH, preprocess, k=10,
        use_reformulation=True, use_reranking=True
    )
    p_full = calculate_precision_at_k(results_full, ground_truth_ids, k=10)

    return {
        'qid': qid,
        'query': query,
        'p@10_baseline': p_baseline,
        'p@10_llm': p_llm,
        'p@10_full': p_full,
        'mejora_llm': p_llm - p_baseline,
        'mejora_full': p_full - p_baseline
    }


# Ejemplo de an√°lisis (necesitar√≠as ground truth real)
print("\n=== M√âTRICAS COMPARATIVAS ===")